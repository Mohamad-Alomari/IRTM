{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import en_core_web_sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('train_script3.csv')\n",
    "test_data = pd.read_csv('test_script3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, test_data]).reset_index()\n",
    "\n",
    "data= data.dropna().reset_index()\n",
    "data = data[['lines', 'character']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def get_tokens(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the emotion lexicon\n",
    "\n",
    "filepath = ('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')\n",
    "emolex_df = pd.read_csv(filepath, names=[\"word\", \"emotion\", \"association\"], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emolex_words = emolex_df.pivot(index='word', columns='emotion', values='association').reset_index()\n",
    "emotions = emolex_words.columns.drop('word')\n",
    "emo_df = pd.DataFrame(0, index=data.index, columns=emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, emo_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \n",
    "def text_emotion(df):\n",
    "\n",
    "\n",
    "    new_df = df.copy()\n",
    "\n",
    "    filepath = ('NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')\n",
    "    emolex_df = pd.read_csv(filepath, names=[\"word\", \"emotion\", \"association\"], sep='\\t')\n",
    "    emolex_words = emolex_df.pivot(index='word', columns='emotion', values='association').reset_index()\n",
    "    emotions = emolex_words.columns.drop('word')\n",
    "    emo_df = pd.DataFrame(0, index=df.index, columns=emotions)\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        document = new_df.lines[i]\n",
    "        document = word_tokenize(df.loc[i]['lines'])\n",
    "        print(i)\n",
    "        \n",
    "        for word in document:\n",
    "            #word = stemmer.stem(word.lower()) Stemmer, there is also an additional example of using the stemming \n",
    "            emo_score = emolex_words[emolex_words.word == word]\n",
    "            if not emo_score.empty:\n",
    "                for emotion in list(emotions):\n",
    "                    emo_df.at[i, emotion] += emo_score[emotion]\n",
    "\n",
    "    new_df = pd.concat([new_df, emo_df], axis=1)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotion_data = text_emotion(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data['word_count'] = emotion_data['lines'].apply(word_tokenize).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data2 = pd.DataFrame(columns =['character', 'anger','anticipation', 'disgust', 'fear', 'joy', 'negative', 'positive', 'sadness', 'surprise', 'trust', 'word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data2['character'] =['Leonard','Sheldon','Penny', 'Howard','Raj','Amy','Bernadette']\n",
    "emotion_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for character in ['Leonard','Sheldon','Penny', 'Howard','Raj','Amy','Bernadette']:\n",
    "    print(character)\n",
    "    columns = emotions + ['word_count']\n",
    "    A = emotion_data2.index[emotion_data2['character'] == character]\n",
    "    idx = A[0]\n",
    "    for emotion in columns:\n",
    "        emotion_data2[emotion][idx] = emotion_data.loc[emotion_data['character'] == character, emotion].sum()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data3 = emotion_data2.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in emotions:\n",
    "    emotion_data3[emotion] = emotion_data3[emotion] / emotion_data3['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in emotions:\n",
    "    for i in range(7):\n",
    "        emotion_data3[emotion][i] = emotion_data3[emotion][i].tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_data3.to_csv('emotions_no_stemming.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
