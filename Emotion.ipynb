{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_emotion(df, column):\n",
    "    '''\n",
    "    Takes a DataFrame and a specified column of text and adds 10 columns to the\n",
    "    DataFrame for each of the 10 emotions in the NRC Emotion Lexicon, with each\n",
    "    column containing the value of the text in that emotions\n",
    "    INPUT: DataFrame, string\n",
    "    OUTPUT: the original DataFrame with ten new columns\n",
    "    '''\n",
    "\n",
    "    new_df = df.copy()\n",
    "\n",
    "    filepath = ('data/'\n",
    "                'NRC-Sentiment-Emotion-Lexicons/'\n",
    "                'NRC-Emotion-Lexicon-v0.92/'\n",
    "                'NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')\n",
    "    emolex_df = pd.read_csv(filepath,\n",
    "                            names=[\"word\", \"emotion\", \"association\"],\n",
    "                            sep='\\t')\n",
    "    emolex_words = emolex_df.pivot(index='word',\n",
    "                                   columns='emotion',\n",
    "                                   values='association').reset_index()\n",
    "    emotions = emolex_words.columns.drop('word')\n",
    "    emo_df = pd.DataFrame(0, index=df.index, columns=emotions)\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    \n",
    "    book = ''\n",
    "    chapter = ''\n",
    "    \n",
    "    with tqdm(total=len(list(new_df.iterrows()))) as pbar:\n",
    "        for i, row in new_df.iterrows():\n",
    "            pbar.update(1)\n",
    "            if row['book'] != book:\n",
    "                print(row['book'])\n",
    "                book = row['book']\n",
    "            if row['chapter_title'] != chapter:\n",
    "                print('   ', row['chapter_title'])\n",
    "                chapter = row['chapter_title']\n",
    "                chap = row['chapter_title']\n",
    "            document = word_tokenize(new_df.loc[i][column])\n",
    "            for word in document:\n",
    "                word = stemmer.stem(word.lower())\n",
    "                emo_score = emolex_words[emolex_words.word == word]\n",
    "                if not emo_score.empty:\n",
    "                    for emotion in list(emotions):\n",
    "                        emo_df.at[i, emotion] += emo_score[emotion]\n",
    "\n",
    "    new_df = pd.concat([new_df, emo_df], axis=1)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-330ac8be6231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'book'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chapter_title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchapter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "data = {'book': [], 'chapter_title': [], 'text': []}\n",
    "\n",
    "for book in hp:\n",
    "    print(book)\n",
    "    for chapter in tqdm(hp[book]):\n",
    "        title = hp[book][chapter][0]\n",
    "#         print('   ', chapter, title)\n",
    "        text = hp[book][chapter][1].replace('\\n', '')\n",
    "        data['book'].append(book)\n",
    "        data['chapter_title'].append(title)\n",
    "        data['text'].append(text)\n",
    "#     print()\n",
    "    \n",
    "hp_df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
